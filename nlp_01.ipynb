{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzrFPFx24gIRen9EvXKAV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyaz-azeem/NLP/blob/main/nlp_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYoi8ErldzdZ",
        "outputId": "01584609-21ab-4cf4-bec4-ee0249c91536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"In a statement, PPP Senator Mustafa Nawaz Khokhar said that the military spokesman’s press conference had exposed Mr Khan’s false claim and the narrative by categorically stating that the word “conspiracy” had not been mentioned in the statement issued by the NSC meeting and a demand of bases had also not been made by the US.\n",
        "\n",
        "“Imran Khan blatantly lied that opposition leaders had approached him though the COAS. Today, the DG ISPR has revealed that it was Imran Khan who had approached the army chief for help,” the PPP senator said.\n",
        "\n",
        "He said Mr Khan should publicly apologise for his lies and attempts to drag security institutions into political matters.\n",
        "\n",
        "Meanwhile, commenting on Mr Khan’s speech at the Peshawar public meeting on Wednesday, PPP Senator Raza Rabbani said the real conspiracy against Pakistan was the systematic dismantling of institutions functioning under the Constitution.\n",
        "\n",
        "He said the attack on the judicial organ of the state was unjustified and uncalled for in the circumstances. He said a situation had arisen where constitutional functionaries had been violating the Constitution and the working of the parliament had been paralysed.\n",
        "\n",
        "Mr Rabbani regretted that the parliament over the past three years had been made redundant as legislation used to be done through ordinances and the parliament was kept in the dark with reference to all major decisions and agreements.\n",
        "\n",
        "He said that media was also subject to harassment, intimidation, removal from assignments and worst press censorship and the security apparatus was being subjected to ridicule. \"\"\""
      ],
      "metadata": {
        "id": "ej8sx1dmd5H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "p7ufQU2telmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  print('\\033[92m{} - {}'.format(i,sentences[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HQgqoMRepgb",
        "outputId": "4783c9b3-e3c9-4519-b9cf-42c49e416151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m0 - In a statement, PPP Senator Mustafa Nawaz Khokhar said that the military spokesman’s press conference had exposed Mr Khan’s false claim and the narrative by categorically stating that the word “conspiracy” had not been mentioned in the statement issued by the NSC meeting and a demand of bases had also not been made by the US.\n",
            "\u001b[92m1 - “Imran Khan blatantly lied that opposition leaders had approached him though the COAS.\n",
            "\u001b[92m2 - Today, the DG ISPR has revealed that it was Imran Khan who had approached the army chief for help,” the PPP senator said.\n",
            "\u001b[92m3 - He said Mr Khan should publicly apologise for his lies and attempts to drag security institutions into political matters.\n",
            "\u001b[92m4 - Meanwhile, commenting on Mr Khan’s speech at the Peshawar public meeting on Wednesday, PPP Senator Raza Rabbani said the real conspiracy against Pakistan was the systematic dismantling of institutions functioning under the Constitution.\n",
            "\u001b[92m5 - He said the attack on the judicial organ of the state was unjustified and uncalled for in the circumstances.\n",
            "\u001b[92m6 - He said a situation had arisen where constitutional functionaries had been violating the Constitution and the working of the parliament had been paralysed.\n",
            "\u001b[92m7 - Mr Rabbani regretted that the parliament over the past three years had been made redundant as legislation used to be done through ordinances and the parliament was kept in the dark with reference to all major decisions and agreements.\n",
            "\u001b[92m8 - He said that media was also subject to harassment, intimidation, removal from assignments and worst press censorship and the security apparatus was being subjected to ridicule.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "PS = PorterStemmer()\n",
        "sentences_PS = sentences.copy()"
      ],
      "metadata": {
        "id": "1y4HvQwOe1XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences_PS)):\n",
        "  words = nltk.word_tokenize(sentences_PS[i])\n",
        "  words = [j.lower() for j in words]\n",
        "  words = [PS.stem(j) for j in words if j not in set(stopwords.words('english'))]\n",
        "  sentences_PS[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "AEJGvgX5fBQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  print('\\033[92m{} - {}'.format(i,sentences[i]))\n",
        "print()\n",
        "for i in range(len(sentences_PS)):\n",
        "  print('\\033[94m{} - {}'.format(i,sentences_PS[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ene795V7hG52",
        "outputId": "ecf0c1cc-5eb5-4be0-8172-f99928fd8915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m0 - In a statement, PPP Senator Mustafa Nawaz Khokhar said that the military spokesman’s press conference had exposed Mr Khan’s false claim and the narrative by categorically stating that the word “conspiracy” had not been mentioned in the statement issued by the NSC meeting and a demand of bases had also not been made by the US.\n",
            "\u001b[92m1 - “Imran Khan blatantly lied that opposition leaders had approached him though the COAS.\n",
            "\u001b[92m2 - Today, the DG ISPR has revealed that it was Imran Khan who had approached the army chief for help,” the PPP senator said.\n",
            "\u001b[92m3 - He said Mr Khan should publicly apologise for his lies and attempts to drag security institutions into political matters.\n",
            "\u001b[92m4 - Meanwhile, commenting on Mr Khan’s speech at the Peshawar public meeting on Wednesday, PPP Senator Raza Rabbani said the real conspiracy against Pakistan was the systematic dismantling of institutions functioning under the Constitution.\n",
            "\u001b[92m5 - He said the attack on the judicial organ of the state was unjustified and uncalled for in the circumstances.\n",
            "\u001b[92m6 - He said a situation had arisen where constitutional functionaries had been violating the Constitution and the working of the parliament had been paralysed.\n",
            "\u001b[92m7 - Mr Rabbani regretted that the parliament over the past three years had been made redundant as legislation used to be done through ordinances and the parliament was kept in the dark with reference to all major decisions and agreements.\n",
            "\u001b[92m8 - He said that media was also subject to harassment, intimidation, removal from assignments and worst press censorship and the security apparatus was being subjected to ridicule.\n",
            "\n",
            "\u001b[94m0 - statement , ppp senat mustafa nawaz khokhar said militari spokesman ’ press confer expos mr khan ’ fals claim narr categor state word “ conspiraci ” mention statement issu nsc meet demand base also made us .\n",
            "\u001b[94m1 - “ imran khan blatantli lie opposit leader approach though coa .\n",
            "\u001b[94m2 - today , dg ispr reveal imran khan approach armi chief help , ” ppp senat said .\n",
            "\u001b[94m3 - said mr khan publicli apologis lie attempt drag secur institut polit matter .\n",
            "\u001b[94m4 - meanwhil , comment mr khan ’ speech peshawar public meet wednesday , ppp senat raza rabbani said real conspiraci pakistan systemat dismantl institut function constitut .\n",
            "\u001b[94m5 - said attack judici organ state unjustifi uncal circumst .\n",
            "\u001b[94m6 - said situat arisen constitut functionari violat constitut work parliament paralys .\n",
            "\u001b[94m7 - mr rabbani regret parliament past three year made redund legisl use done ordin parliament kept dark refer major decis agreement .\n",
            "\u001b[94m8 - said media also subject harass , intimid , remov assign worst press censorship secur apparatu subject ridicul .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_para = \"\"\"ریاض (اُردو پوائنٹ اخبارتازہ ترین۔ 14 اپریل2022ء) سعودی شہزادے ولید بن طلال نے ٹوئٹر کی فروخت کیلئے ایلون مسک کی پیش کش مسترد کر دی، ٹیسلا کمپنی کے مالک مائیکرو بلاگنگ ویب سائٹ کی خریداری کیلئے فی شیئر 54 ڈالر کے حساب سے 43 ارب ڈالرز کی پیش کش کر چکے۔ تفصیلات کے مطابق ایلون مسک کی جانب سے 43 ارب ڈالرز میں ٹوئٹر کی خریداری کی پیش کش کیے جانے کے بعد سعودی شہزادے ولید بن طلال کی جانب سے ردعمل دیا گیا ہے۔\n",
        "\n",
        "\n",
        "\n",
        "کنگڈم ہولڈنگ کمپنی کے مالک ولید بن طلال نے ٹیسلا کمپنی کے مالک کی پیش کش کو مسترد کرتے ہوئے کہا ہے کہ چونکہ 54 عشاریہ 20 ڈالرز فی شیئر قیمت، ٹوئٹر کی حقیقی مالیت اور گروتھ کے امکانات کے مقابلے میں کہیں کم ہے، اس لیے ٹوئٹر کے سب سے بڑے شیئر ہولڈرز میں سے ایک ہونے کی حیثیت سے ایلون مسک کی پیش کش کو مسترد کرتا ہوں۔\n",
        "\n",
        "اس سے قبل ایلون مسک نے کہا تھا کہ ٹوئٹر ایک سوشل میڈیا پلیٹ فارم کے طور پر اپنے اندر غیر معمولی امکانات لیے ہوئے ہے اور میں ان امکانات کو استعمال میں لاؤں گا۔ ایلون مسک نے یہ بات ٹوئٹر کے انتظامی بورڈ کے نام لکھے گئے ایک خط میں کہی۔ ایلون مسک نے اپنے خط میں ٹوئٹر کے بورڈ کو پیشکش کی کہ وہ اس کمپنی کے 100 فیصد شیئرز کو فی شیئر 54.20 امریکی ڈالر کی قیمت میں خریدنے پر تیار ہیں۔ اس سے قبل ایلون مسک کی طرف سے ٹوئٹر کے نو فیصد سے زائد حصص خریدے جانے کے بعد کمپنی کے بورڈ نے انہیں کمپنی کے سب سے بڑے شیئر ہولڈر بن جانے پر یہ پیشکش کی تھی کہ وہ چاہیں تو ٹوئٹر کے انتظامی بورڈ کے رکن بھی بن سکتے ہیں۔ تاہم ٹیسلا کے مالک ایلون مسک نے یہ پیش کش مسترد کر دی تھی۔\"\"\""
      ],
      "metadata": {
        "id": "ZdzB_PVgfaN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_sentences = nltk.sent_tokenize(urdu_para)"
      ],
      "metadata": {
        "id": "F0yKhT4oflvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(urdu_sentences)):\n",
        "  print('{} - {}'.format(i, urdu_sentences[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhFrksOTfsDk",
        "outputId": "89f25258-2ce3-4a60-a0fa-ed18b347ca14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - ریاض (اُردو پوائنٹ اخبارتازہ ترین۔ 14 اپریل2022ء) سعودی شہزادے ولید بن طلال نے ٹوئٹر کی فروخت کیلئے ایلون مسک کی پیش کش مسترد کر دی، ٹیسلا کمپنی کے مالک مائیکرو بلاگنگ ویب سائٹ کی خریداری کیلئے فی شیئر 54 ڈالر کے حساب سے 43 ارب ڈالرز کی پیش کش کر چکے۔ تفصیلات کے مطابق ایلون مسک کی جانب سے 43 ارب ڈالرز میں ٹوئٹر کی خریداری کی پیش کش کیے جانے کے بعد سعودی شہزادے ولید بن طلال کی جانب سے ردعمل دیا گیا ہے۔\n",
            "\n",
            "\n",
            "\n",
            "کنگڈم ہولڈنگ کمپنی کے مالک ولید بن طلال نے ٹیسلا کمپنی کے مالک کی پیش کش کو مسترد کرتے ہوئے کہا ہے کہ چونکہ 54 عشاریہ 20 ڈالرز فی شیئر قیمت، ٹوئٹر کی حقیقی مالیت اور گروتھ کے امکانات کے مقابلے میں کہیں کم ہے، اس لیے ٹوئٹر کے سب سے بڑے شیئر ہولڈرز میں سے ایک ہونے کی حیثیت سے ایلون مسک کی پیش کش کو مسترد کرتا ہوں۔\n",
            "\n",
            "اس سے قبل ایلون مسک نے کہا تھا کہ ٹوئٹر ایک سوشل میڈیا پلیٹ فارم کے طور پر اپنے اندر غیر معمولی امکانات لیے ہوئے ہے اور میں ان امکانات کو استعمال میں لاؤں گا۔ ایلون مسک نے یہ بات ٹوئٹر کے انتظامی بورڈ کے نام لکھے گئے ایک خط میں کہی۔ ایلون مسک نے اپنے خط میں ٹوئٹر کے بورڈ کو پیشکش کی کہ وہ اس کمپنی کے 100 فیصد شیئرز کو فی شیئر 54.20 امریکی ڈالر کی قیمت میں خریدنے پر تیار ہیں۔ اس سے قبل ایلون مسک کی طرف سے ٹوئٹر کے نو فیصد سے زائد حصص خریدے جانے کے بعد کمپنی کے بورڈ نے انہیں کمپنی کے سب سے بڑے شیئر ہولڈر بن جانے پر یہ پیشکش کی تھی کہ وہ چاہیں تو ٹوئٹر کے انتظامی بورڈ کے رکن بھی بن سکتے ہیں۔ تاہم ٹیسلا کے مالک ایلون مسک نے یہ پیش کش مسترد کر دی تھی۔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(urdu_sentences)):\n",
        "  words = nltk.word_tokenize(urdu_sentences[i])\n",
        "  words = [j.lower() for j in words]\n",
        "  words = [PS.stem(j) for j in words if j not in set(stopwords.words('urdu'))]\n",
        "  urdu_sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "9zZ6B8Dufy0B",
        "outputId": "51dc1246-1ca0-49eb-8e2f-d55dcfff1a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3d4e11ac106f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murdu_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urdu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0murdu_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3d4e11ac106f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murdu_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urdu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0murdu_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0m\u001b[1;32m     23\u001b[0m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such file or directory: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/root/nltk_data/corpora/stopwords/urdu'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "WN = WordNetLemmatizer()\n",
        "sentences_WN = sentences.copy()"
      ],
      "metadata": {
        "id": "NCFGXwV0gAlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences_WN)):\n",
        "  words = nltk.word_tokenize(sentences_WN[i])\n",
        "  words = [j.lower() for j in words]\n",
        "  words = [WN.lemmatize(j) for j in words if j not in set(stopwords.words('english'))]\n",
        "  sentences_WN[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "ttBdUlt8gxq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  print('\\033[92m{} - {}'.format(i+1,sentences[i]))\n",
        "print()\n",
        "for i in range(len(sentences_PS)):\n",
        "  print('\\033[94m{} - {}'.format(i+1,sentences_PS[i]))\n",
        "print()\n",
        "for i in range(len(sentences_WN)):\n",
        "  print('\\033[95m{} - {}'.format(i+1,sentences_WN[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCczabiVhEW3",
        "outputId": "030b5f90-38ed-4b02-9708-f61928251b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m1 - In a statement, PPP Senator Mustafa Nawaz Khokhar said that the military spokesman’s press conference had exposed Mr Khan’s false claim and the narrative by categorically stating that the word “conspiracy” had not been mentioned in the statement issued by the NSC meeting and a demand of bases had also not been made by the US.\n",
            "\u001b[92m2 - “Imran Khan blatantly lied that opposition leaders had approached him though the COAS.\n",
            "\u001b[92m3 - Today, the DG ISPR has revealed that it was Imran Khan who had approached the army chief for help,” the PPP senator said.\n",
            "\u001b[92m4 - He said Mr Khan should publicly apologise for his lies and attempts to drag security institutions into political matters.\n",
            "\u001b[92m5 - Meanwhile, commenting on Mr Khan’s speech at the Peshawar public meeting on Wednesday, PPP Senator Raza Rabbani said the real conspiracy against Pakistan was the systematic dismantling of institutions functioning under the Constitution.\n",
            "\u001b[92m6 - He said the attack on the judicial organ of the state was unjustified and uncalled for in the circumstances.\n",
            "\u001b[92m7 - He said a situation had arisen where constitutional functionaries had been violating the Constitution and the working of the parliament had been paralysed.\n",
            "\u001b[92m8 - Mr Rabbani regretted that the parliament over the past three years had been made redundant as legislation used to be done through ordinances and the parliament was kept in the dark with reference to all major decisions and agreements.\n",
            "\u001b[92m9 - He said that media was also subject to harassment, intimidation, removal from assignments and worst press censorship and the security apparatus was being subjected to ridicule.\n",
            "\n",
            "\u001b[94m1 - statement , ppp senat mustafa nawaz khokhar said militari spokesman ’ press confer expos mr khan ’ fals claim narr categor state word “ conspiraci ” mention statement issu nsc meet demand base also made us .\n",
            "\u001b[94m2 - “ imran khan blatantli lie opposit leader approach though coa .\n",
            "\u001b[94m3 - today , dg ispr reveal imran khan approach armi chief help , ” ppp senat said .\n",
            "\u001b[94m4 - said mr khan publicli apologis lie attempt drag secur institut polit matter .\n",
            "\u001b[94m5 - meanwhil , comment mr khan ’ speech peshawar public meet wednesday , ppp senat raza rabbani said real conspiraci pakistan systemat dismantl institut function constitut .\n",
            "\u001b[94m6 - said attack judici organ state unjustifi uncal circumst .\n",
            "\u001b[94m7 - said situat arisen constitut functionari violat constitut work parliament paralys .\n",
            "\u001b[94m8 - mr rabbani regret parliament past three year made redund legisl use done ordin parliament kept dark refer major decis agreement .\n",
            "\u001b[94m9 - said media also subject harass , intimid , remov assign worst press censorship secur apparatu subject ridicul .\n",
            "\n",
            "\u001b[95m1 - statement , ppp senator mustafa nawaz khokhar said military spokesman ’ press conference exposed mr khan ’ false claim narrative categorically stating word “ conspiracy ” mentioned statement issued nsc meeting demand base also made u .\n",
            "\u001b[95m2 - “ imran khan blatantly lied opposition leader approached though coas .\n",
            "\u001b[95m3 - today , dg ispr revealed imran khan approached army chief help , ” ppp senator said .\n",
            "\u001b[95m4 - said mr khan publicly apologise lie attempt drag security institution political matter .\n",
            "\u001b[95m5 - meanwhile , commenting mr khan ’ speech peshawar public meeting wednesday , ppp senator raza rabbani said real conspiracy pakistan systematic dismantling institution functioning constitution .\n",
            "\u001b[95m6 - said attack judicial organ state unjustified uncalled circumstance .\n",
            "\u001b[95m7 - said situation arisen constitutional functionary violating constitution working parliament paralysed .\n",
            "\u001b[95m8 - mr rabbani regretted parliament past three year made redundant legislation used done ordinance parliament kept dark reference major decision agreement .\n",
            "\u001b[95m9 - said medium also subject harassment , intimidation , removal assignment worst press censorship security apparatus subjected ridicule .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sentences_bow = sentences.copy()\n",
        "corpus_PS = []\n",
        "corpus_WN = []\n",
        "for i in range(len(sentences_bow)):\n",
        "  review = re.sub('[^a-zA-Z]', ' ',sentences_bow[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "\n",
        "  review_PS = [PS.stem(j) for j in review if j not in set(stopwords.words('english'))]\n",
        "  review_PS = ' '.join(review_PS)\n",
        "  corpus_PS.append(review_PS)\n",
        "\n",
        "  revie_WN = [WN.lemmatize(j) for j in review if j not in set(stopwords.words('english'))]\n",
        "  review_WN = ' '.join(revie_WN)\n",
        "  corpus_WN.append(review_WN)"
      ],
      "metadata": {
        "id": "FsgUA8GHhad_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences_bow)):\n",
        "  print('\\033[92m{} - {}'.format(i+1,sentences_bow[i]))\n",
        "print()\n",
        "for i in range(len(corpus_PS)):\n",
        "  print('\\033[94m{} - {}'.format(i+1,corpus_PS[i]))\n",
        "print()\n",
        "for i in range(len(corpus_WN)):\n",
        "  print('\\033[95m{} - {}'.format(i+1,corpus_WN[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CtAnnFjiMCT",
        "outputId": "541d3c0b-01ee-4388-df20-5e939b0086f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m1 - In a statement, PPP Senator Mustafa Nawaz Khokhar said that the military spokesman’s press conference had exposed Mr Khan’s false claim and the narrative by categorically stating that the word “conspiracy” had not been mentioned in the statement issued by the NSC meeting and a demand of bases had also not been made by the US.\n",
            "\u001b[92m2 - “Imran Khan blatantly lied that opposition leaders had approached him though the COAS.\n",
            "\u001b[92m3 - Today, the DG ISPR has revealed that it was Imran Khan who had approached the army chief for help,” the PPP senator said.\n",
            "\u001b[92m4 - He said Mr Khan should publicly apologise for his lies and attempts to drag security institutions into political matters.\n",
            "\u001b[92m5 - Meanwhile, commenting on Mr Khan’s speech at the Peshawar public meeting on Wednesday, PPP Senator Raza Rabbani said the real conspiracy against Pakistan was the systematic dismantling of institutions functioning under the Constitution.\n",
            "\u001b[92m6 - He said the attack on the judicial organ of the state was unjustified and uncalled for in the circumstances.\n",
            "\u001b[92m7 - He said a situation had arisen where constitutional functionaries had been violating the Constitution and the working of the parliament had been paralysed.\n",
            "\u001b[92m8 - Mr Rabbani regretted that the parliament over the past three years had been made redundant as legislation used to be done through ordinances and the parliament was kept in the dark with reference to all major decisions and agreements.\n",
            "\u001b[92m9 - He said that media was also subject to harassment, intimidation, removal from assignments and worst press censorship and the security apparatus was being subjected to ridicule.\n",
            "\n",
            "\u001b[94m1 - statement ppp senat mustafa nawaz khokhar said militari spokesman press confer expos mr khan fals claim narr categor state word conspiraci mention statement issu nsc meet demand base also made us\n",
            "\u001b[94m2 - imran khan blatantli lie opposit leader approach though coa\n",
            "\u001b[94m3 - today dg ispr reveal imran khan approach armi chief help ppp senat said\n",
            "\u001b[94m4 - said mr khan publicli apologis lie attempt drag secur institut polit matter\n",
            "\u001b[94m5 - meanwhil comment mr khan speech peshawar public meet wednesday ppp senat raza rabbani said real conspiraci pakistan systemat dismantl institut function constitut\n",
            "\u001b[94m6 - said attack judici organ state unjustifi uncal circumst\n",
            "\u001b[94m7 - said situat arisen constitut functionari violat constitut work parliament paralys\n",
            "\u001b[94m8 - mr rabbani regret parliament past three year made redund legisl use done ordin parliament kept dark refer major decis agreement\n",
            "\u001b[94m9 - said media also subject harass intimid remov assign worst press censorship secur apparatu subject ridicul\n",
            "\n",
            "\u001b[95m1 - statement ppp senator mustafa nawaz khokhar said military spokesman press conference exposed mr khan false claim narrative categorically stating word conspiracy mentioned statement issued nsc meeting demand base also made u\n",
            "\u001b[95m2 - imran khan blatantly lied opposition leader approached though coas\n",
            "\u001b[95m3 - today dg ispr revealed imran khan approached army chief help ppp senator said\n",
            "\u001b[95m4 - said mr khan publicly apologise lie attempt drag security institution political matter\n",
            "\u001b[95m5 - meanwhile commenting mr khan speech peshawar public meeting wednesday ppp senator raza rabbani said real conspiracy pakistan systematic dismantling institution functioning constitution\n",
            "\u001b[95m6 - said attack judicial organ state unjustified uncalled circumstance\n",
            "\u001b[95m7 - said situation arisen constitutional functionary violating constitution working parliament paralysed\n",
            "\u001b[95m8 - mr rabbani regretted parliament past three year made redundant legislation used done ordinance parliament kept dark reference major decision agreement\n",
            "\u001b[95m9 - said medium also subject harassment intimidation removal assignment worst press censorship security apparatus subjected ridicule\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "CV = CountVectorizer()\n",
        "X = CV.fit_transform(corpus_WN).toarray()\n",
        "CV.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFIgTK9Mij7v",
        "outputId": "b8c91e8a-2137-4314-d5be-88c1bf880333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['agreement', 'also', 'apologise', 'apparatus', 'approached',\n",
              "       'arisen', 'army', 'assignment', 'attack', 'attempt', 'base',\n",
              "       'blatantly', 'categorically', 'censorship', 'chief',\n",
              "       'circumstance', 'claim', 'coas', 'commenting', 'conference',\n",
              "       'conspiracy', 'constitution', 'constitutional', 'dark', 'decision',\n",
              "       'demand', 'dg', 'dismantling', 'done', 'drag', 'exposed', 'false',\n",
              "       'functionary', 'functioning', 'harassment', 'help', 'imran',\n",
              "       'institution', 'intimidation', 'ispr', 'issued', 'judicial',\n",
              "       'kept', 'khan', 'khokhar', 'leader', 'legislation', 'lie', 'lied',\n",
              "       'made', 'major', 'matter', 'meanwhile', 'medium', 'meeting',\n",
              "       'mentioned', 'military', 'mr', 'mustafa', 'narrative', 'nawaz',\n",
              "       'nsc', 'opposition', 'ordinance', 'organ', 'pakistan', 'paralysed',\n",
              "       'parliament', 'past', 'peshawar', 'political', 'ppp', 'press',\n",
              "       'public', 'publicly', 'rabbani', 'raza', 'real', 'redundant',\n",
              "       'reference', 'regretted', 'removal', 'revealed', 'ridicule',\n",
              "       'said', 'security', 'senator', 'situation', 'speech', 'spokesman',\n",
              "       'state', 'statement', 'stating', 'subject', 'subjected',\n",
              "       'systematic', 'though', 'three', 'today', 'uncalled',\n",
              "       'unjustified', 'used', 'violating', 'wednesday', 'word', 'working',\n",
              "       'worst', 'year'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(CV.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESNrcOeKi56i",
        "outputId": "ba1a557b-9f85-447d-8fa2-b838e0b2a259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "CV2 = TfidfVectorizer()\n",
        "X2 = CV2.fit_transform(corpus_WN).toarray()\n",
        "CV2.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr0agjc2i-WU",
        "outputId": "370574d4-294c-439d-aaa1-377adcdb0478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['agreement', 'also', 'apologise', 'apparatus', 'approached',\n",
              "       'arisen', 'army', 'assignment', 'attack', 'attempt', 'base',\n",
              "       'blatantly', 'categorically', 'censorship', 'chief',\n",
              "       'circumstance', 'claim', 'coas', 'commenting', 'conference',\n",
              "       'conspiracy', 'constitution', 'constitutional', 'dark', 'decision',\n",
              "       'demand', 'dg', 'dismantling', 'done', 'drag', 'exposed', 'false',\n",
              "       'functionary', 'functioning', 'harassment', 'help', 'imran',\n",
              "       'institution', 'intimidation', 'ispr', 'issued', 'judicial',\n",
              "       'kept', 'khan', 'khokhar', 'leader', 'legislation', 'lie', 'lied',\n",
              "       'made', 'major', 'matter', 'meanwhile', 'medium', 'meeting',\n",
              "       'mentioned', 'military', 'mr', 'mustafa', 'narrative', 'nawaz',\n",
              "       'nsc', 'opposition', 'ordinance', 'organ', 'pakistan', 'paralysed',\n",
              "       'parliament', 'past', 'peshawar', 'political', 'ppp', 'press',\n",
              "       'public', 'publicly', 'rabbani', 'raza', 'real', 'redundant',\n",
              "       'reference', 'regretted', 'removal', 'revealed', 'ridicule',\n",
              "       'said', 'security', 'senator', 'situation', 'speech', 'spokesman',\n",
              "       'state', 'statement', 'stating', 'subject', 'subjected',\n",
              "       'systematic', 'though', 'three', 'today', 'uncalled',\n",
              "       'unjustified', 'used', 'violating', 'wednesday', 'word', 'working',\n",
              "       'worst', 'year'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(CV2.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlX4v2bujJM_",
        "outputId": "9a29f358-a372-4dc8-bfc2-00d3d4c2541d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "messages = pd.read_csv('/content/SMSSpamCollection',\n",
        "                       sep = '\\t',\n",
        "                       names = [\"label\",\"message\"])"
      ],
      "metadata": {
        "id": "XTeUMwqGjSVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5fQrwuM6ji01",
        "outputId": "b12a6386-a0ec-48b3-c8b8-e59c753bbaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label                                            message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ce33d3e-2f4b-409a-84f6-d1b97cc65f38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ce33d3e-2f4b-409a-84f6-d1b97cc65f38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ce33d3e-2f4b-409a-84f6-d1b97cc65f38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ce33d3e-2f4b-409a-84f6-d1b97cc65f38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_SMS_PS = [] \n",
        "corpus_SMS_WN = []\n",
        "for i in range(len(messages)):\n",
        "  review_SMS = re.sub('[^a-zA-Z]',\n",
        "                  ' ',\n",
        "                  messages[\"message\"][i])\n",
        "  review_SMS = review_SMS.lower()\n",
        "  review_SMS = review_SMS.split()\n",
        "\n",
        "  review_SMS_PS = [PS.stem(j) for j in review_SMS if j not in set(stopwords.words('english'))]\n",
        "  review_SMS_PS = ' '.join(review_SMS_PS)\n",
        "  corpus_SMS_PS.append(review_SMS_PS)\n",
        "\n",
        "  review_SMS_WN = [WN.lemmatize(j) for j in review_SMS if j not in set(stopwords.words('english'))]\n",
        "  review_SMS_WN = ' '.join(review_SMS_WN)\n",
        "  corpus_SMS_WN.append(review_SMS_WN)"
      ],
      "metadata": {
        "id": "q4iSCtxIjm82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,500,100):\n",
        "  print('\\033[92m{} - {}'.format(i+1,messages['message'][i]))\n",
        "  print('\\033[94m-{} - {}'.format(i+1,corpus_SMS_PS[i]))\n",
        "  print('\\033[95m--{} - {}'.format(i+1,corpus_SMS_WN[i]))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIL2rHvVk3ZA",
        "outputId": "df7d589e-f6d2-47cd-d1c9-3477e8c3db33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m1 - Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\u001b[94m-1 - go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n",
            "\u001b[95m--1 - go jurong point crazy available bugis n great world la e buffet cine got amore wat\n",
            "\n",
            "\u001b[92m101 - Please don't text me anymore. I have nothing else to say.\n",
            "\u001b[94m-101 - pleas text anymor noth els say\n",
            "\u001b[95m--101 - please text anymore nothing else say\n",
            "\n",
            "\u001b[92m201 - Found it, ENC  &lt;#&gt; , where you at?\n",
            "\u001b[94m-201 - found enc lt gt\n",
            "\u001b[95m--201 - found enc lt gt\n",
            "\n",
            "\u001b[92m301 - Need a coffee run tomo?Can't believe it's that time of week already\n",
            "\u001b[94m-301 - need coffe run tomo believ time week alreadi\n",
            "\u001b[95m--301 - need coffee run tomo believe time week already\n",
            "\n",
            "\u001b[92m401 - Hmmm...k...but i want to change the field quickly da:-)i wanna get system administrator or network administrator..\n",
            "\u001b[94m-401 - hmmm k want chang field quickli da wanna get system administr network administr\n",
            "\u001b[95m--401 - hmmm k want change field quickly da wanna get system administrator network administrator\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BOW\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "CV3 = CountVectorizer(max_features = 2500)\n",
        "X_PS = CV3.fit_transform(corpus_SMS_PS).toarray()\n",
        "X_WN = CV3.fit_transform(corpus_SMS_WN).toarray()"
      ],
      "metadata": {
        "id": "hIw2ZumSlpQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(messages['label'])\n",
        "print('\\033[94m{}'.format(y))\n",
        "y=y.iloc[:,-1].values\n",
        "print('\\033[95m{}'.format(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RJckKWrl-59",
        "outputId": "74fe1758-ebe2-4b86-ac41-38290723c687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m      ham  spam\n",
            "0       1     0\n",
            "1       1     0\n",
            "2       0     1\n",
            "3       1     0\n",
            "4       1     0\n",
            "...   ...   ...\n",
            "5567    0     1\n",
            "5568    1     0\n",
            "5569    1     0\n",
            "5570    1     0\n",
            "5571    1     0\n",
            "\n",
            "[5572 rows x 2 columns]\n",
            "\u001b[95m[0 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_PS, X_test_PS, y_train_PS,y_test_PS = train_test_split(X_PS,y,test_size = 0.2,random_state=0)\n",
        "X_train_WN, X_test_WN, y_train_WN,y_test_WN = train_test_split(X_WN,y,test_size = 0.2,random_state=0)"
      ],
      "metadata": {
        "id": "ecNMS1RwmQ2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detected_model_PS = MultinomialNB().fit(X_train_PS,y_train_PS)\n",
        "spam_detected_model_WN = MultinomialNB().fit(X_train_WN,y_train_WN)"
      ],
      "metadata": {
        "id": "BbZrvIDqmrk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_PS = spam_detected_model_PS.predict(X_test_PS)\n",
        "y_pred_WN = spam_detected_model_WN.predict(X_test_WN)"
      ],
      "metadata": {
        "id": "KEgdRDlJm8aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm_PS = confusion_matrix(y_test_PS,y_pred_PS)\n",
        "cm_WN = confusion_matrix(y_test_WN,y_pred_WN)\n",
        "print('\\033[94m{}'.format(cm_PS))\n",
        "print('\\033[95m{}'.format(cm_WN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBNaGmpym8fD",
        "outputId": "626a36f7-9968-4e15-f161-424535dc2b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[[946   9]\n",
            " [  7 153]]\n",
            "\u001b[95m[[946   9]\n",
            " [ 10 150]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_PS=accuracy_score(y_test_PS,y_pred_PS)\n",
        "accuracy_WN=accuracy_score(y_test_WN,y_pred_WN)\n",
        "print('\\033[94m{}'.format(accuracy_PS))\n",
        "print('\\033[95m{}'.format(accuracy_WN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8PT1oelnd7s",
        "outputId": "3c75e023-e6ac-487e-fa58-4e0d8db6f593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m0.9856502242152466\n",
            "\u001b[95m0.9829596412556054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "CV4 = TfidfVectorizer(max_features = 2500)\n",
        "X_PS = CV4.fit_transform(corpus_SMS_PS).toarray()\n",
        "X_WN = CV4.fit_transform(corpus_SMS_WN).toarrxay()\n",
        "X_train_PS, X_test_PS, y_train_PS,y_test_PS = train_test_split(X_PS,y,test_size = 0.2,random_state=0)\n",
        "X_train_WN, X_test_WN, y_train_WN,y_test_WN = train_test_split(X_WN,y,test_size = 0.2,random_state=0)\n",
        "y_pred_PS = spam_detected_model_PS.predict(X_test_PS)\n",
        "y_pred_WN = spam_detected_model_WN.predict(X_test_WN)\n",
        "cm_PS = confusion_matrix(y_test_PS,y_pred_PS)\n",
        "cm_WN = confusion_matrix(y_test_WN,y_pred_WN)\n",
        "print('\\033[94m{}'.format(cm_PS))\n",
        "print('\\033[95m{}'.format(cm_WN))\n",
        "accuracy_PS=accuracy_score(y_test_PS,y_pred_PS)\n",
        "accuracy_WN=accuracy_score(y_test_WN,y_pred_WN)\n",
        "print('\\033[94m{}'.format(accuracy_PS))\n",
        "print('\\033[95m{}'.format(accuracy_WN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ij43g6n4w9",
        "outputId": "c7e19043-c855-40f2-d658-bf9fc7640004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[[953   2]\n",
            " [ 17 143]]\n",
            "\u001b[95m[[953   2]\n",
            " [ 18 142]]\n",
            "\u001b[94m0.9829596412556054\n",
            "\u001b[95m0.9820627802690582\n"
          ]
        }
      ]
    }
  ]
}